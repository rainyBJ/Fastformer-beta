 Ed: 0, train_loss: 1.70751, acc: 0.14062
 Ed: 640, train_loss: 2.10192, acc: 0.21307
 Ed: 1280, train_loss: 1.90711, acc: 0.22470
 Ed: 1920, train_loss: 1.82726, acc: 0.23589
 Ed: 2560, train_loss: 1.79183, acc: 0.23857
 Ed: 3200, train_loss: 1.75659, acc: 0.23958
 Ed: 3840, train_loss: 1.72817, acc: 0.24103
 Ed: 4480, train_loss: 1.70498, acc: 0.24582
 Ed: 5120, train_loss: 1.68443, acc: 0.25116
 Ed: 5760, train_loss: 1.66529, acc: 0.25738
 Ed: 6400, train_loss: 1.65507, acc: 0.26176
 Ed: 7040, train_loss: 1.64411, acc: 0.26422
 Ed: 7680, train_loss: 1.63216, acc: 0.26847
 Ed: 8320, train_loss: 1.62956, acc: 0.27052
 Ed: 8960, train_loss: 1.62382, acc: 0.27360
 Ed: 9600, train_loss: 1.62096, acc: 0.27432
 Ed: 10240, train_loss: 1.61144, acc: 0.27902
 Ed: 10880, train_loss: 1.60166, acc: 0.28618
 Ed: 11520, train_loss: 1.59201, acc: 0.29118
 Ed: 12160, train_loss: 1.58715, acc: 0.29303
 Ed: 12800, train_loss: 1.58030, acc: 0.29509
 Ed: 13440, train_loss: 1.57299, acc: 0.29895
 Ed: 14080, train_loss: 1.56735, acc: 0.30204
 Ed: 14720, train_loss: 1.55961, acc: 0.30499
 Ed: 15360, train_loss: 1.55164, acc: 0.30822
 Ed: 16000, train_loss: 1.54656, acc: 0.31032
 Ed: 16640, train_loss: 1.54106, acc: 0.31262
 Ed: 17280, train_loss: 1.53323, acc: 0.31648
 Ed: 17920, train_loss: 1.52754, acc: 0.32001
 Ed: 18560, train_loss: 1.52213, acc: 0.32206
 Ed: 19200, train_loss: 1.51742, acc: 0.32428
 Ed: 19840, train_loss: 1.51104, acc: 0.32722
 Ed: 20480, train_loss: 1.50480, acc: 0.33090
 Ed: 21120, train_loss: 1.50000, acc: 0.33322
 Ed: 21760, train_loss: 1.49413, acc: 0.33610
 Ed: 22400, train_loss: 1.49067, acc: 0.33752
 Ed: 23040, train_loss: 1.48558, acc: 0.34037
 Ed: 23680, train_loss: 1.48162, acc: 0.34232
 Ed: 24320, train_loss: 1.47715, acc: 0.34432
 Ed: 24960, train_loss: 1.47469, acc: 0.34555
 Ed: 25600, train_loss: 1.47070, acc: 0.34776
 Ed: 26240, train_loss: 1.46644, acc: 0.34968
 Ed: 26880, train_loss: 1.46324, acc: 0.35058
 Ed: 27520, train_loss: 1.45960, acc: 0.35202
 Ed: 28160, train_loss: 1.45642, acc: 0.35289
 Ed: 28800, train_loss: 1.45271, acc: 0.35494
 Ed: 29440, train_loss: 1.44867, acc: 0.35680
 Ed: 30080, train_loss: 1.44668, acc: 0.35765
 Ed: 30720, train_loss: 1.44524, acc: 0.35834
 Ed: 31360, train_loss: 1.44263, acc: 0.36014
 Ed: 32000, train_loss: 1.44031, acc: 0.36143
 Ed: 32640, train_loss: 1.43761, acc: 0.36231
 Ed: 33280, train_loss: 1.43519, acc: 0.36345
 Ed: 33920, train_loss: 1.43293, acc: 0.36438
 Ed: 34560, train_loss: 1.43050, acc: 0.36518
 Ed: 35200, train_loss: 1.42939, acc: 0.36610
 Ed: 35840, train_loss: 1.42673, acc: 0.36726
 Ed: 36480, train_loss: 1.42455, acc: 0.36830
 Ed: 37120, train_loss: 1.42173, acc: 0.37013
 Ed: 37760, train_loss: 1.42027, acc: 0.37095
 Ed: 38400, train_loss: 1.41835, acc: 0.37185
 Ed: 39040, train_loss: 1.41574, acc: 0.37298
 Ed: 39680, train_loss: 1.41291, acc: 0.37409
accuracy: 
0.3964
macrof: 
0.424
 Ed: 0, train_loss: 1.07827, acc: 0.54688
 Ed: 640, train_loss: 1.15910, acc: 0.50000
 Ed: 1280, train_loss: 1.21504, acc: 0.47991
 Ed: 1920, train_loss: 1.21294, acc: 0.46925
 Ed: 2560, train_loss: 1.19521, acc: 0.47447
 Ed: 3200, train_loss: 1.18613, acc: 0.47917
 Ed: 3840, train_loss: 1.18755, acc: 0.48079
 Ed: 4480, train_loss: 1.18665, acc: 0.47623
 Ed: 5120, train_loss: 1.18450, acc: 0.47743
 Ed: 5760, train_loss: 1.18675, acc: 0.48008
 Ed: 6400, train_loss: 1.18573, acc: 0.47912
 Ed: 7040, train_loss: 1.18760, acc: 0.47706
 Ed: 7680, train_loss: 1.18828, acc: 0.47792
 Ed: 8320, train_loss: 1.19645, acc: 0.47424
 Ed: 8960, train_loss: 1.19751, acc: 0.47329
 Ed: 9600, train_loss: 1.19410, acc: 0.47413
 Ed: 10240, train_loss: 1.19754, acc: 0.47428
 Ed: 10880, train_loss: 1.19811, acc: 0.47533
 Ed: 11520, train_loss: 1.19642, acc: 0.47678
 Ed: 12160, train_loss: 1.19713, acc: 0.47497
 Ed: 12800, train_loss: 1.19713, acc: 0.47466
 Ed: 13440, train_loss: 1.19762, acc: 0.47527
 Ed: 14080, train_loss: 1.19628, acc: 0.47639
 Ed: 14720, train_loss: 1.19390, acc: 0.47707
 Ed: 15360, train_loss: 1.19239, acc: 0.47672
 Ed: 16000, train_loss: 1.19133, acc: 0.47709
 Ed: 16640, train_loss: 1.18984, acc: 0.47785
 Ed: 17280, train_loss: 1.18818, acc: 0.47913
 Ed: 17920, train_loss: 1.18790, acc: 0.47937
 Ed: 18560, train_loss: 1.18682, acc: 0.47981
 Ed: 19200, train_loss: 1.18694, acc: 0.47950
 Ed: 19840, train_loss: 1.18541, acc: 0.48071
 Ed: 20480, train_loss: 1.18690, acc: 0.48024
 Ed: 21120, train_loss: 1.18520, acc: 0.48126
 Ed: 21760, train_loss: 1.18422, acc: 0.48254
 Ed: 22400, train_loss: 1.18394, acc: 0.48246
 Ed: 23040, train_loss: 1.18413, acc: 0.48238
 Ed: 23680, train_loss: 1.18461, acc: 0.48181
 Ed: 24320, train_loss: 1.18314, acc: 0.48196
 Ed: 24960, train_loss: 1.18117, acc: 0.48258
 Ed: 25600, train_loss: 1.17977, acc: 0.48340
 Ed: 26240, train_loss: 1.17901, acc: 0.48350
 Ed: 26880, train_loss: 1.17930, acc: 0.48270
 Ed: 27520, train_loss: 1.17992, acc: 0.48242
 Ed: 28160, train_loss: 1.17962, acc: 0.48306
 Ed: 28800, train_loss: 1.17768, acc: 0.48399
 Ed: 29440, train_loss: 1.17772, acc: 0.48434
 Ed: 30080, train_loss: 1.17728, acc: 0.48487
 Ed: 30720, train_loss: 1.17795, acc: 0.48415
 Ed: 31360, train_loss: 1.17743, acc: 0.48406
 Ed: 32000, train_loss: 1.17976, acc: 0.48366
 Ed: 32640, train_loss: 1.17884, acc: 0.48434
 Ed: 33280, train_loss: 1.17881, acc: 0.48473
 Ed: 33920, train_loss: 1.17744, acc: 0.48552
 Ed: 34560, train_loss: 1.17714, acc: 0.48599
 Ed: 35200, train_loss: 1.17664, acc: 0.48596
 Ed: 35840, train_loss: 1.17619, acc: 0.48652
 Ed: 36480, train_loss: 1.17663, acc: 0.48610
 Ed: 37120, train_loss: 1.17656, acc: 0.48610
 Ed: 37760, train_loss: 1.17660, acc: 0.48564
 Ed: 38400, train_loss: 1.17629, acc: 0.48567
 Ed: 39040, train_loss: 1.17481, acc: 0.48645
 Ed: 39680, train_loss: 1.17495, acc: 0.48586
accuracy: 
0.4082
macrof: 
0.423
 Ed: 0, train_loss: 1.12035, acc: 0.40625
 Ed: 640, train_loss: 1.04194, acc: 0.54830
 Ed: 1280, train_loss: 1.00512, acc: 0.55952
 Ed: 1920, train_loss: 1.00790, acc: 0.56250
 Ed: 2560, train_loss: 1.02147, acc: 0.55869
 Ed: 3200, train_loss: 1.03074, acc: 0.55208
 Ed: 3840, train_loss: 1.03583, acc: 0.54713
 Ed: 4480, train_loss: 1.03699, acc: 0.54996
 Ed: 5120, train_loss: 1.03709, acc: 0.54958
 Ed: 5760, train_loss: 1.03624, acc: 0.54842
 Ed: 6400, train_loss: 1.03885, acc: 0.54672
 Ed: 7040, train_loss: 1.03736, acc: 0.54702
 Ed: 7680, train_loss: 1.03515, acc: 0.54739
 Ed: 8320, train_loss: 1.03139, acc: 0.54974
 Ed: 8960, train_loss: 1.03072, acc: 0.55053
 Ed: 9600, train_loss: 1.03359, acc: 0.54636
 Ed: 10240, train_loss: 1.03358, acc: 0.54678
 Ed: 10880, train_loss: 1.03282, acc: 0.54578
 Ed: 11520, train_loss: 1.03430, acc: 0.54636
 Ed: 12160, train_loss: 1.04373, acc: 0.54581
 Ed: 12800, train_loss: 1.04534, acc: 0.54462
 Ed: 13440, train_loss: 1.04751, acc: 0.54310
 Ed: 14080, train_loss: 1.05032, acc: 0.54426
 Ed: 14720, train_loss: 1.04982, acc: 0.54552
 Ed: 15360, train_loss: 1.05322, acc: 0.54538
 Ed: 16000, train_loss: 1.05431, acc: 0.54432
 Ed: 16640, train_loss: 1.05561, acc: 0.54400
 Ed: 17280, train_loss: 1.05440, acc: 0.54463
 Ed: 17920, train_loss: 1.05429, acc: 0.54560
 Ed: 18560, train_loss: 1.05412, acc: 0.54559
 Ed: 19200, train_loss: 1.05719, acc: 0.54350
 Ed: 19840, train_loss: 1.05686, acc: 0.54276
 Ed: 20480, train_loss: 1.05759, acc: 0.54181
 Ed: 21120, train_loss: 1.05833, acc: 0.54248
 Ed: 21760, train_loss: 1.06073, acc: 0.54101
 Ed: 22400, train_loss: 1.05992, acc: 0.54140
 Ed: 23040, train_loss: 1.06328, acc: 0.54138
 Ed: 23680, train_loss: 1.06226, acc: 0.54115
 Ed: 24320, train_loss: 1.06414, acc: 0.54068
 Ed: 24960, train_loss: 1.06275, acc: 0.54132
 Ed: 25600, train_loss: 1.06344, acc: 0.54099
 Ed: 26240, train_loss: 1.06223, acc: 0.54106
 Ed: 26880, train_loss: 1.06222, acc: 0.54149
 Ed: 27520, train_loss: 1.06123, acc: 0.54187
 Ed: 28160, train_loss: 1.06071, acc: 0.54142
 Ed: 28800, train_loss: 1.05943, acc: 0.54196
 Ed: 29440, train_loss: 1.05981, acc: 0.54176
 Ed: 30080, train_loss: 1.05885, acc: 0.54223
 Ed: 30720, train_loss: 1.05791, acc: 0.54272
 Ed: 31360, train_loss: 1.05795, acc: 0.54232
 Ed: 32000, train_loss: 1.05751, acc: 0.54263
 Ed: 32640, train_loss: 1.05752, acc: 0.54314
 Ed: 33280, train_loss: 1.05731, acc: 0.54310
 Ed: 33920, train_loss: 1.05697, acc: 0.54317
 Ed: 34560, train_loss: 1.05744, acc: 0.54361
 Ed: 35200, train_loss: 1.05625, acc: 0.54441
 Ed: 35840, train_loss: 1.05481, acc: 0.54523
 Ed: 36480, train_loss: 1.05459, acc: 0.54526
 Ed: 37120, train_loss: 1.05452, acc: 0.54518
 Ed: 37760, train_loss: 1.05393, acc: 0.54532
 Ed: 38400, train_loss: 1.05416, acc: 0.54459
 Ed: 39040, train_loss: 1.05465, acc: 0.54427
 Ed: 39680, train_loss: 1.05498, acc: 0.54386
accuracy: 
0.4318
macrof: 
0.4277
