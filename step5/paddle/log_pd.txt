 Ed: 0, train_loss: 1.68796, acc: 0.10938
 Ed: 640, train_loss: 1.58878, acc: 0.51847
 Ed: 1280, train_loss: 1.47376, acc: 0.51711
 Ed: 1920, train_loss: 1.39159, acc: 0.53730
 Ed: 2560, train_loss: 1.34365, acc: 0.55564
 Ed: 3200, train_loss: 1.31628, acc: 0.55729
 Ed: 3840, train_loss: 1.27930, acc: 0.56737
 Ed: 4480, train_loss: 1.27204, acc: 0.56778
 Ed: 5120, train_loss: 1.25878, acc: 0.57215
 Ed: 5760, train_loss: 1.23688, acc: 0.57916
 Ed: 6400, train_loss: 1.22619, acc: 0.58168
 Ed: 7040, train_loss: 1.21600, acc: 0.58502
 Ed: 7680, train_loss: 1.20365, acc: 0.58858
 Ed: 8320, train_loss: 1.19013, acc: 0.59256
 Ed: 8960, train_loss: 1.19221, acc: 0.58799
 Ed: 9600, train_loss: 1.18257, acc: 0.59085
 Ed: 10240, train_loss: 1.17851, acc: 0.59094
 Ed: 10880, train_loss: 1.17278, acc: 0.59101
 Ed: 11520, train_loss: 1.16712, acc: 0.59228
 Ed: 12160, train_loss: 1.15905, acc: 0.59334
 Ed: 12800, train_loss: 1.15350, acc: 0.59398
 Ed: 13440, train_loss: 1.14793, acc: 0.59493
 Ed: 14080, train_loss: 1.14342, acc: 0.59545
 Ed: 14720, train_loss: 1.13705, acc: 0.59700
 Ed: 15360, train_loss: 1.13001, acc: 0.59920
 Ed: 16000, train_loss: 1.12347, acc: 0.60097
 Ed: 16640, train_loss: 1.12111, acc: 0.60075
 Ed: 17280, train_loss: 1.11611, acc: 0.60055
 Ed: 17920, train_loss: 1.11427, acc: 0.60098
 Ed: 18560, train_loss: 1.11315, acc: 0.60035
 Ed: 19200, train_loss: 1.10810, acc: 0.60148
 Ed: 19840, train_loss: 1.10485, acc: 0.60194
 Ed: 20480, train_loss: 1.10325, acc: 0.60144
 Ed: 21120, train_loss: 1.10100, acc: 0.60126
 Ed: 21760, train_loss: 1.09780, acc: 0.60172
 Ed: 22400, train_loss: 1.09262, acc: 0.60319
 Ed: 23040, train_loss: 1.09124, acc: 0.60353
 Ed: 23680, train_loss: 1.08972, acc: 0.60314
 Ed: 24320, train_loss: 1.08896, acc: 0.60244
 Ed: 24960, train_loss: 1.08701, acc: 0.60298
 Ed: 25600, train_loss: 1.08532, acc: 0.60279
 Ed: 26240, train_loss: 1.08264, acc: 0.60363
 Ed: 26880, train_loss: 1.07932, acc: 0.60485
 Ed: 27520, train_loss: 1.07785, acc: 0.60441
 Ed: 28160, train_loss: 1.07512, acc: 0.60495
 Ed: 28800, train_loss: 1.07216, acc: 0.60560
 Ed: 29440, train_loss: 1.07101, acc: 0.60521
 Ed: 30080, train_loss: 1.06889, acc: 0.60573
 Ed: 30720, train_loss: 1.06667, acc: 0.60609
 Ed: 31360, train_loss: 1.06577, acc: 0.60600
 Ed: 32000, train_loss: 1.06413, acc: 0.60588
 Ed: 32640, train_loss: 1.06108, acc: 0.60644
 Ed: 33280, train_loss: 1.05902, acc: 0.60698
 Ed: 33920, train_loss: 1.05732, acc: 0.60734
 Ed: 34560, train_loss: 1.05489, acc: 0.60834
 Ed: 35200, train_loss: 1.05280, acc: 0.60864
 Ed: 35840, train_loss: 1.05114, acc: 0.60871
 Ed: 36480, train_loss: 1.05010, acc: 0.60866
 Ed: 37120, train_loss: 1.04802, acc: 0.60924
 Ed: 37760, train_loss: 1.04629, acc: 0.60969
 Ed: 38400, train_loss: 1.04419, acc: 0.61065
 Ed: 39040, train_loss: 1.04333, acc: 0.61137
 Ed: 39680, train_loss: 1.04093, acc: 0.61227
accuracy: 
0.636
macrof: 
0.3801
 Ed: 0, train_loss: 0.85675, acc: 0.67188
 Ed: 640, train_loss: 0.93401, acc: 0.64915
 Ed: 1280, train_loss: 0.90546, acc: 0.64286
 Ed: 1920, train_loss: 0.90489, acc: 0.64214
 Ed: 2560, train_loss: 0.90242, acc: 0.64139
 Ed: 3200, train_loss: 0.89857, acc: 0.64583
 Ed: 3840, train_loss: 0.90288, acc: 0.64472
 Ed: 4480, train_loss: 0.89553, acc: 0.64921
 Ed: 5120, train_loss: 0.88801, acc: 0.65432
 Ed: 5760, train_loss: 0.88880, acc: 0.65608
 Ed: 6400, train_loss: 0.88520, acc: 0.65718
 Ed: 7040, train_loss: 0.88613, acc: 0.65512
 Ed: 7680, train_loss: 0.88572, acc: 0.65483
 Ed: 8320, train_loss: 0.88821, acc: 0.65434
 Ed: 8960, train_loss: 0.88739, acc: 0.65592
 Ed: 9600, train_loss: 0.88512, acc: 0.65573
 Ed: 10240, train_loss: 0.88396, acc: 0.65771
 Ed: 10880, train_loss: 0.88409, acc: 0.65735
 Ed: 11520, train_loss: 0.88446, acc: 0.65668
 Ed: 12160, train_loss: 0.88331, acc: 0.65723
 Ed: 12800, train_loss: 0.88383, acc: 0.65648
 Ed: 13440, train_loss: 0.88291, acc: 0.65677
 Ed: 14080, train_loss: 0.88108, acc: 0.65802
 Ed: 14720, train_loss: 0.87913, acc: 0.65902
 Ed: 15360, train_loss: 0.87962, acc: 0.65891
 Ed: 16000, train_loss: 0.87861, acc: 0.65992
 Ed: 16640, train_loss: 0.87683, acc: 0.66092
 Ed: 17280, train_loss: 0.87328, acc: 0.66253
 Ed: 17920, train_loss: 0.87284, acc: 0.66270
 Ed: 18560, train_loss: 0.87406, acc: 0.66178
 Ed: 19200, train_loss: 0.87535, acc: 0.66082
 Ed: 19840, train_loss: 0.87516, acc: 0.66002
 Ed: 20480, train_loss: 0.87218, acc: 0.66165
 Ed: 21120, train_loss: 0.87090, acc: 0.66234
 Ed: 21760, train_loss: 0.87109, acc: 0.66239
 Ed: 22400, train_loss: 0.87087, acc: 0.66262
 Ed: 23040, train_loss: 0.87071, acc: 0.66318
 Ed: 23680, train_loss: 0.87104, acc: 0.66303
 Ed: 24320, train_loss: 0.87059, acc: 0.66310
 Ed: 24960, train_loss: 0.86912, acc: 0.66348
 Ed: 25600, train_loss: 0.87023, acc: 0.66326
 Ed: 26240, train_loss: 0.87000, acc: 0.66363
 Ed: 26880, train_loss: 0.87199, acc: 0.66304
 Ed: 27520, train_loss: 0.87201, acc: 0.66234
 Ed: 28160, train_loss: 0.87284, acc: 0.66217
 Ed: 28800, train_loss: 0.87252, acc: 0.66204
 Ed: 29440, train_loss: 0.87234, acc: 0.66181
 Ed: 30080, train_loss: 0.87217, acc: 0.66199
 Ed: 30720, train_loss: 0.87261, acc: 0.66151
 Ed: 31360, train_loss: 0.87346, acc: 0.66106
 Ed: 32000, train_loss: 0.87318, acc: 0.66046
 Ed: 32640, train_loss: 0.87181, acc: 0.66133
 Ed: 33280, train_loss: 0.87133, acc: 0.66105
 Ed: 33920, train_loss: 0.87101, acc: 0.66122
 Ed: 34560, train_loss: 0.87111, acc: 0.66099
 Ed: 35200, train_loss: 0.87157, acc: 0.66042
 Ed: 35840, train_loss: 0.87152, acc: 0.66020
 Ed: 36480, train_loss: 0.87097, acc: 0.66027
 Ed: 37120, train_loss: 0.87054, acc: 0.66047
 Ed: 37760, train_loss: 0.86984, acc: 0.66101
 Ed: 38400, train_loss: 0.87009, acc: 0.66057
 Ed: 39040, train_loss: 0.87065, acc: 0.66021
 Ed: 39680, train_loss: 0.86953, acc: 0.66063
accuracy: 
0.6158
macrof: 
0.5128
 Ed: 0, train_loss: 0.83722, acc: 0.67188
 Ed: 640, train_loss: 0.78183, acc: 0.67614
 Ed: 1280, train_loss: 0.77836, acc: 0.68452
 Ed: 1920, train_loss: 0.77059, acc: 0.69355
 Ed: 2560, train_loss: 0.77859, acc: 0.68979
 Ed: 3200, train_loss: 0.75858, acc: 0.69455
 Ed: 3840, train_loss: 0.76055, acc: 0.69493
 Ed: 4480, train_loss: 0.75673, acc: 0.69740
 Ed: 5120, train_loss: 0.75318, acc: 0.69792
 Ed: 5760, train_loss: 0.75147, acc: 0.69952
 Ed: 6400, train_loss: 0.75244, acc: 0.69910
 Ed: 7040, train_loss: 0.75113, acc: 0.70073
 Ed: 7680, train_loss: 0.75389, acc: 0.69925
 Ed: 8320, train_loss: 0.75564, acc: 0.69812
 Ed: 8960, train_loss: 0.75607, acc: 0.69747
 Ed: 9600, train_loss: 0.75615, acc: 0.69692
 Ed: 10240, train_loss: 0.75865, acc: 0.69507
 Ed: 10880, train_loss: 0.76127, acc: 0.69481
 Ed: 11520, train_loss: 0.76205, acc: 0.69475
 Ed: 12160, train_loss: 0.76404, acc: 0.69380
 Ed: 12800, train_loss: 0.76322, acc: 0.69488
 Ed: 13440, train_loss: 0.76072, acc: 0.69624
 Ed: 14080, train_loss: 0.76461, acc: 0.69372
 Ed: 14720, train_loss: 0.76426, acc: 0.69386
 Ed: 15360, train_loss: 0.76997, acc: 0.69236
 Ed: 16000, train_loss: 0.77195, acc: 0.69211
 Ed: 16640, train_loss: 0.77254, acc: 0.69163
 Ed: 17280, train_loss: 0.77961, acc: 0.69107
 Ed: 17920, train_loss: 0.78294, acc: 0.68961
 Ed: 18560, train_loss: 0.78405, acc: 0.68911
 Ed: 19200, train_loss: 0.78290, acc: 0.68994
 Ed: 19840, train_loss: 0.78241, acc: 0.68976
 Ed: 20480, train_loss: 0.78295, acc: 0.68935
 Ed: 21120, train_loss: 0.78611, acc: 0.68826
 Ed: 21760, train_loss: 0.78613, acc: 0.68736
 Ed: 22400, train_loss: 0.78518, acc: 0.68768
 Ed: 23040, train_loss: 0.78481, acc: 0.68759
 Ed: 23680, train_loss: 0.78678, acc: 0.68801
 Ed: 24320, train_loss: 0.78758, acc: 0.68754
 Ed: 24960, train_loss: 0.78696, acc: 0.68770
 Ed: 25600, train_loss: 0.78551, acc: 0.68820
 Ed: 26240, train_loss: 0.78626, acc: 0.68803
 Ed: 26880, train_loss: 0.78534, acc: 0.68832
 Ed: 27520, train_loss: 0.78624, acc: 0.68797
 Ed: 28160, train_loss: 0.78539, acc: 0.68817
 Ed: 28800, train_loss: 0.78548, acc: 0.68788
 Ed: 29440, train_loss: 0.78600, acc: 0.68821
 Ed: 30080, train_loss: 0.78704, acc: 0.68813
 Ed: 30720, train_loss: 0.78677, acc: 0.68825
 Ed: 31360, train_loss: 0.78772, acc: 0.68807
 Ed: 32000, train_loss: 0.78799, acc: 0.68819
 Ed: 32640, train_loss: 0.78840, acc: 0.68799
 Ed: 33280, train_loss: 0.78956, acc: 0.68747
 Ed: 33920, train_loss: 0.79048, acc: 0.68697
 Ed: 34560, train_loss: 0.79108, acc: 0.68704
 Ed: 35200, train_loss: 0.79201, acc: 0.68702
 Ed: 35840, train_loss: 0.79446, acc: 0.68686
 Ed: 36480, train_loss: 0.79541, acc: 0.68649
 Ed: 37120, train_loss: 0.79588, acc: 0.68653
 Ed: 37760, train_loss: 0.79677, acc: 0.68642
 Ed: 38400, train_loss: 0.79664, acc: 0.68651
 Ed: 39040, train_loss: 0.79665, acc: 0.68648
 Ed: 39680, train_loss: 0.79715, acc: 0.68622
accuracy: 
0.6504
macrof: 
0.4368
