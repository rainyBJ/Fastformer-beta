 Ed: 0, train_loss: 1.68796, acc: 0.10938
 Ed: 640, train_loss: 1.58887, acc: 0.51847
 Ed: 1280, train_loss: 1.47397, acc: 0.51637
 Ed: 1920, train_loss: 1.39178, acc: 0.53679
 Ed: 2560, train_loss: 1.34375, acc: 0.55488
 Ed: 3200, train_loss: 1.31632, acc: 0.55637
 Ed: 3840, train_loss: 1.27927, acc: 0.56685
 Ed: 4480, train_loss: 1.27197, acc: 0.56756
 Ed: 5120, train_loss: 1.25882, acc: 0.57215
 Ed: 5760, train_loss: 1.23675, acc: 0.57916
 Ed: 6400, train_loss: 1.22602, acc: 0.58153
 Ed: 7040, train_loss: 1.21584, acc: 0.58488
 Ed: 7680, train_loss: 1.20348, acc: 0.58858
 Ed: 8320, train_loss: 1.19004, acc: 0.59256
 Ed: 8960, train_loss: 1.19225, acc: 0.58799
 Ed: 9600, train_loss: 1.18263, acc: 0.59096
 Ed: 10240, train_loss: 1.17861, acc: 0.59123
 Ed: 10880, train_loss: 1.17295, acc: 0.59119
 Ed: 11520, train_loss: 1.16740, acc: 0.59280
 Ed: 12160, train_loss: 1.15934, acc: 0.59391
 Ed: 12800, train_loss: 1.15379, acc: 0.59445
 Ed: 13440, train_loss: 1.14820, acc: 0.59553
 Ed: 14080, train_loss: 1.14364, acc: 0.59580
 Ed: 14720, train_loss: 1.13719, acc: 0.59733
 Ed: 15360, train_loss: 1.13013, acc: 0.59933
 Ed: 16000, train_loss: 1.12365, acc: 0.60103
 Ed: 16640, train_loss: 1.12121, acc: 0.60075
 Ed: 17280, train_loss: 1.11616, acc: 0.60038
 Ed: 17920, train_loss: 1.11440, acc: 0.60092
 Ed: 18560, train_loss: 1.11354, acc: 0.60035
 Ed: 19200, train_loss: 1.10834, acc: 0.60148
 Ed: 19840, train_loss: 1.10503, acc: 0.60204
 Ed: 20480, train_loss: 1.10341, acc: 0.60159
 Ed: 21120, train_loss: 1.10131, acc: 0.60130
 Ed: 21760, train_loss: 1.09808, acc: 0.60181
 Ed: 22400, train_loss: 1.09299, acc: 0.60319
 Ed: 23040, train_loss: 1.09163, acc: 0.60336
 Ed: 23680, train_loss: 1.09013, acc: 0.60293
 Ed: 24320, train_loss: 1.08923, acc: 0.60220
 Ed: 24960, train_loss: 1.08719, acc: 0.60266
 Ed: 25600, train_loss: 1.08560, acc: 0.60279
 Ed: 26240, train_loss: 1.08263, acc: 0.60363
 Ed: 26880, train_loss: 1.07937, acc: 0.60459
 Ed: 27520, train_loss: 1.07792, acc: 0.60386
 Ed: 28160, train_loss: 1.07501, acc: 0.60456
 Ed: 28800, train_loss: 1.07217, acc: 0.60543
 Ed: 29440, train_loss: 1.07114, acc: 0.60504
 Ed: 30080, train_loss: 1.06918, acc: 0.60563
 Ed: 30720, train_loss: 1.06692, acc: 0.60606
 Ed: 31360, train_loss: 1.06610, acc: 0.60635
 Ed: 32000, train_loss: 1.06462, acc: 0.60635
 Ed: 32640, train_loss: 1.06177, acc: 0.60693
 Ed: 33280, train_loss: 1.06001, acc: 0.60731
 Ed: 33920, train_loss: 1.05821, acc: 0.60764
 Ed: 34560, train_loss: 1.05553, acc: 0.60851
 Ed: 35200, train_loss: 1.05342, acc: 0.60869
 Ed: 35840, train_loss: 1.05193, acc: 0.60851
 Ed: 36480, train_loss: 1.05126, acc: 0.60834
 Ed: 37120, train_loss: 1.04909, acc: 0.60876
 Ed: 37760, train_loss: 1.04732, acc: 0.60908
 Ed: 38400, train_loss: 1.04517, acc: 0.60995
 Ed: 39040, train_loss: 1.04414, acc: 0.61060
 Ed: 39680, train_loss: 1.04174, acc: 0.61131
accuracy: 
0.628
macrof: 
0.3585
 Ed: 0, train_loss: 0.85748, acc: 0.68750
 Ed: 640, train_loss: 0.91504, acc: 0.65767
 Ed: 1280, train_loss: 0.89519, acc: 0.64881
 Ed: 1920, train_loss: 0.89615, acc: 0.64617
 Ed: 2560, train_loss: 0.92020, acc: 0.64253
 Ed: 3200, train_loss: 0.92316, acc: 0.64400
 Ed: 3840, train_loss: 0.92640, acc: 0.64139
 Ed: 4480, train_loss: 0.92369, acc: 0.64261
 Ed: 5120, train_loss: 0.92014, acc: 0.64410
 Ed: 5760, train_loss: 0.91394, acc: 0.64698
 Ed: 6400, train_loss: 0.90966, acc: 0.64774
 Ed: 7040, train_loss: 0.91046, acc: 0.64682
 Ed: 7680, train_loss: 0.90819, acc: 0.64669
 Ed: 8320, train_loss: 0.91087, acc: 0.64659
 Ed: 8960, train_loss: 0.91094, acc: 0.64871
 Ed: 9600, train_loss: 0.90738, acc: 0.64870
 Ed: 10240, train_loss: 0.90452, acc: 0.65062
 Ed: 10880, train_loss: 0.90227, acc: 0.65077
 Ed: 11520, train_loss: 0.90251, acc: 0.65012
 Ed: 12160, train_loss: 0.90048, acc: 0.65118
 Ed: 12800, train_loss: 0.90137, acc: 0.64980
 Ed: 13440, train_loss: 0.90070, acc: 0.65010
 Ed: 14080, train_loss: 0.89941, acc: 0.65123
 Ed: 14720, train_loss: 0.89718, acc: 0.65219
 Ed: 15360, train_loss: 0.89718, acc: 0.65242
 Ed: 16000, train_loss: 0.89606, acc: 0.65332
 Ed: 16640, train_loss: 0.89364, acc: 0.65386
 Ed: 17280, train_loss: 0.88969, acc: 0.65631
 Ed: 17920, train_loss: 0.88856, acc: 0.65642
 Ed: 18560, train_loss: 0.88944, acc: 0.65555
 Ed: 19200, train_loss: 0.89027, acc: 0.65469
 Ed: 19840, train_loss: 0.88991, acc: 0.65449
 Ed: 20480, train_loss: 0.88718, acc: 0.65620
 Ed: 21120, train_loss: 0.88561, acc: 0.65677
 Ed: 21760, train_loss: 0.88538, acc: 0.65648
 Ed: 22400, train_loss: 0.88502, acc: 0.65634
 Ed: 23040, train_loss: 0.88453, acc: 0.65664
 Ed: 23680, train_loss: 0.88421, acc: 0.65684
 Ed: 24320, train_loss: 0.88337, acc: 0.65732
 Ed: 24960, train_loss: 0.88162, acc: 0.65753
 Ed: 25600, train_loss: 0.88290, acc: 0.65754
 Ed: 26240, train_loss: 0.88248, acc: 0.65796
 Ed: 26880, train_loss: 0.88562, acc: 0.65747
 Ed: 27520, train_loss: 0.88518, acc: 0.65708
 Ed: 28160, train_loss: 0.88496, acc: 0.65724
 Ed: 28800, train_loss: 0.88395, acc: 0.65753
 Ed: 29440, train_loss: 0.88351, acc: 0.65710
 Ed: 30080, train_loss: 0.88274, acc: 0.65725
 Ed: 30720, train_loss: 0.88304, acc: 0.65690
 Ed: 31360, train_loss: 0.88333, acc: 0.65673
 Ed: 32000, train_loss: 0.88279, acc: 0.65647
 Ed: 32640, train_loss: 0.88116, acc: 0.65726
 Ed: 33280, train_loss: 0.88061, acc: 0.65733
 Ed: 33920, train_loss: 0.88035, acc: 0.65743
 Ed: 34560, train_loss: 0.88019, acc: 0.65746
 Ed: 35200, train_loss: 0.88049, acc: 0.65696
 Ed: 35840, train_loss: 0.88031, acc: 0.65689
 Ed: 36480, train_loss: 0.87991, acc: 0.65707
 Ed: 37120, train_loss: 0.87951, acc: 0.65714
 Ed: 37760, train_loss: 0.87831, acc: 0.65773
 Ed: 38400, train_loss: 0.87841, acc: 0.65752
 Ed: 39040, train_loss: 0.87853, acc: 0.65717
 Ed: 39680, train_loss: 0.87743, acc: 0.65733
accuracy: 
0.6178
macrof: 
0.4182
 Ed: 0, train_loss: 0.84886, acc: 0.70312
 Ed: 640, train_loss: 0.78091, acc: 0.69318
 Ed: 1280, train_loss: 0.79384, acc: 0.68527
 Ed: 1920, train_loss: 0.78338, acc: 0.69254
 Ed: 2560, train_loss: 0.78731, acc: 0.68483
 Ed: 3200, train_loss: 0.76679, acc: 0.69179
 Ed: 3840, train_loss: 0.76885, acc: 0.68981
 Ed: 4480, train_loss: 0.76489, acc: 0.69146
 Ed: 5120, train_loss: 0.76087, acc: 0.69232
 Ed: 5760, train_loss: 0.75842, acc: 0.69454
 Ed: 6400, train_loss: 0.75781, acc: 0.69570
 Ed: 7040, train_loss: 0.75581, acc: 0.69820
 Ed: 7680, train_loss: 0.75901, acc: 0.69525
 Ed: 8320, train_loss: 0.75942, acc: 0.69430
 Ed: 8960, train_loss: 0.75785, acc: 0.69426
 Ed: 9600, train_loss: 0.75910, acc: 0.69474
 Ed: 10240, train_loss: 0.76131, acc: 0.69284
 Ed: 10880, train_loss: 0.76224, acc: 0.69317
 Ed: 11520, train_loss: 0.76283, acc: 0.69242
 Ed: 12160, train_loss: 0.76478, acc: 0.69118
 Ed: 12800, train_loss: 0.76263, acc: 0.69271
 Ed: 13440, train_loss: 0.75919, acc: 0.69483
 Ed: 14080, train_loss: 0.76314, acc: 0.69316
 Ed: 14720, train_loss: 0.76189, acc: 0.69399
 Ed: 15360, train_loss: 0.77456, acc: 0.69334
 Ed: 16000, train_loss: 0.77537, acc: 0.69310
 Ed: 16640, train_loss: 0.77563, acc: 0.69277
 Ed: 17280, train_loss: 0.77935, acc: 0.69200
 Ed: 17920, train_loss: 0.78343, acc: 0.69006
 Ed: 18560, train_loss: 0.78530, acc: 0.68959
 Ed: 19200, train_loss: 0.78461, acc: 0.69015
 Ed: 19840, train_loss: 0.78600, acc: 0.68986
 Ed: 20480, train_loss: 0.78809, acc: 0.68935
 Ed: 21120, train_loss: 0.79631, acc: 0.68811
 Ed: 21760, train_loss: 0.79847, acc: 0.68736
 Ed: 22400, train_loss: 0.79813, acc: 0.68741
 Ed: 23040, train_loss: 0.79741, acc: 0.68707
 Ed: 23680, train_loss: 0.79893, acc: 0.68699
 Ed: 24320, train_loss: 0.79944, acc: 0.68701
 Ed: 24960, train_loss: 0.79934, acc: 0.68702
 Ed: 25600, train_loss: 0.79806, acc: 0.68727
 Ed: 26240, train_loss: 0.79997, acc: 0.68716
 Ed: 26880, train_loss: 0.79913, acc: 0.68702
 Ed: 27520, train_loss: 0.79958, acc: 0.68641
 Ed: 28160, train_loss: 0.79840, acc: 0.68683
 Ed: 28800, train_loss: 0.79770, acc: 0.68688
 Ed: 29440, train_loss: 0.79782, acc: 0.68723
 Ed: 30080, train_loss: 0.79747, acc: 0.68737
 Ed: 30720, train_loss: 0.79590, acc: 0.68815
 Ed: 31360, train_loss: 0.79618, acc: 0.68814
 Ed: 32000, train_loss: 0.79599, acc: 0.68803
 Ed: 32640, train_loss: 0.79561, acc: 0.68817
 Ed: 33280, train_loss: 0.79565, acc: 0.68783
 Ed: 33920, train_loss: 0.79572, acc: 0.68732
 Ed: 34560, train_loss: 0.79567, acc: 0.68718
 Ed: 35200, train_loss: 0.79632, acc: 0.68724
 Ed: 35840, train_loss: 0.79557, acc: 0.68717
 Ed: 36480, train_loss: 0.79629, acc: 0.68679
 Ed: 37120, train_loss: 0.79663, acc: 0.68683
 Ed: 37760, train_loss: 0.79722, acc: 0.68676
 Ed: 38400, train_loss: 0.79652, acc: 0.68706
 Ed: 39040, train_loss: 0.79661, acc: 0.68696
 Ed: 39680, train_loss: 0.79647, acc: 0.68687
accuracy: 
0.6438
macrof: 
0.4149
