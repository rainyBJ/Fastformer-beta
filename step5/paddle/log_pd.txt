 Ed: 0, train_loss: 1.70668, acc: 0.14062
 Ed: 640, train_loss: 2.08539, acc: 0.22017
 Ed: 1280, train_loss: 1.89908, acc: 0.22991
 Ed: 1920, train_loss: 1.83071, acc: 0.22833
 Ed: 2560, train_loss: 1.79657, acc: 0.22866
 Ed: 3200, train_loss: 1.76598, acc: 0.23192
 Ed: 3840, train_loss: 1.73528, acc: 0.23899
 Ed: 4480, train_loss: 1.70815, acc: 0.24648
 Ed: 5120, train_loss: 1.68531, acc: 0.25328
 Ed: 5760, train_loss: 1.66299, acc: 0.25841
 Ed: 6400, train_loss: 1.64810, acc: 0.26671
 Ed: 7040, train_loss: 1.63513, acc: 0.27196
 Ed: 7680, train_loss: 1.62495, acc: 0.27544
 Ed: 8320, train_loss: 1.61404, acc: 0.27910
 Ed: 8960, train_loss: 1.60812, acc: 0.28081
 Ed: 9600, train_loss: 1.59942, acc: 0.28435
 Ed: 10240, train_loss: 1.58860, acc: 0.28940
 Ed: 10880, train_loss: 1.57941, acc: 0.29432
 Ed: 11520, train_loss: 1.56947, acc: 0.29981
 Ed: 12160, train_loss: 1.56427, acc: 0.30178
 Ed: 12800, train_loss: 1.55882, acc: 0.30309
 Ed: 13440, train_loss: 1.55210, acc: 0.30687
 Ed: 14080, train_loss: 1.54670, acc: 0.31158
 Ed: 14720, train_loss: 1.54042, acc: 0.31439
 Ed: 15360, train_loss: 1.53321, acc: 0.31730
 Ed: 16000, train_loss: 1.52781, acc: 0.32022
 Ed: 16640, train_loss: 1.52373, acc: 0.32136
 Ed: 17280, train_loss: 1.51596, acc: 0.32449
 Ed: 17920, train_loss: 1.51156, acc: 0.32746
 Ed: 18560, train_loss: 1.50618, acc: 0.32947
 Ed: 19200, train_loss: 1.50175, acc: 0.33119
 Ed: 19840, train_loss: 1.49599, acc: 0.33425
 Ed: 20480, train_loss: 1.49141, acc: 0.33625
 Ed: 21120, train_loss: 1.48718, acc: 0.33823
 Ed: 21760, train_loss: 1.48071, acc: 0.34100
 Ed: 22400, train_loss: 1.47741, acc: 0.34273
 Ed: 23040, train_loss: 1.47305, acc: 0.34505
 Ed: 23680, train_loss: 1.46886, acc: 0.34695
 Ed: 24320, train_loss: 1.46403, acc: 0.34920
 Ed: 24960, train_loss: 1.46161, acc: 0.35066
 Ed: 25600, train_loss: 1.45784, acc: 0.35298
 Ed: 26240, train_loss: 1.45370, acc: 0.35557
 Ed: 26880, train_loss: 1.45052, acc: 0.35685
 Ed: 27520, train_loss: 1.44759, acc: 0.35825
 Ed: 28160, train_loss: 1.44489, acc: 0.35927
 Ed: 28800, train_loss: 1.44120, acc: 0.36093
 Ed: 29440, train_loss: 1.43716, acc: 0.36266
 Ed: 30080, train_loss: 1.43542, acc: 0.36292
 Ed: 30720, train_loss: 1.43421, acc: 0.36334
 Ed: 31360, train_loss: 1.43132, acc: 0.36526
 Ed: 32000, train_loss: 1.42915, acc: 0.36664
 Ed: 32640, train_loss: 1.42645, acc: 0.36797
 Ed: 33280, train_loss: 1.42474, acc: 0.36864
 Ed: 33920, train_loss: 1.42270, acc: 0.36947
 Ed: 34560, train_loss: 1.42052, acc: 0.37044
 Ed: 35200, train_loss: 1.41824, acc: 0.37143
 Ed: 35840, train_loss: 1.41647, acc: 0.37235
 Ed: 36480, train_loss: 1.41462, acc: 0.37300
 Ed: 37120, train_loss: 1.41155, acc: 0.37446
 Ed: 37760, train_loss: 1.41044, acc: 0.37526
 Ed: 38400, train_loss: 1.40874, acc: 0.37630
 Ed: 39040, train_loss: 1.40611, acc: 0.37745
 Ed: 39680, train_loss: 1.40337, acc: 0.37875
accuracy: 
0.4162
macrof: 
0.4229
 Ed: 0, train_loss: 1.02171, acc: 0.57812
 Ed: 640, train_loss: 1.17826, acc: 0.49858
 Ed: 1280, train_loss: 1.24767, acc: 0.47098
 Ed: 1920, train_loss: 1.24340, acc: 0.46069
 Ed: 2560, train_loss: 1.22158, acc: 0.46723
 Ed: 3200, train_loss: 1.20369, acc: 0.47610
 Ed: 3840, train_loss: 1.19966, acc: 0.47848
 Ed: 4480, train_loss: 1.19811, acc: 0.47623
 Ed: 5120, train_loss: 1.19415, acc: 0.47666
 Ed: 5760, train_loss: 1.19231, acc: 0.47751
 Ed: 6400, train_loss: 1.19276, acc: 0.47834
 Ed: 7040, train_loss: 1.19525, acc: 0.47565
 Ed: 7680, train_loss: 1.19425, acc: 0.47689
 Ed: 8320, train_loss: 1.19707, acc: 0.47471
 Ed: 8960, train_loss: 1.19918, acc: 0.47462
 Ed: 9600, train_loss: 1.19558, acc: 0.47475
 Ed: 10240, train_loss: 1.20306, acc: 0.47486
 Ed: 10880, train_loss: 1.20375, acc: 0.47496
 Ed: 11520, train_loss: 1.20188, acc: 0.47583
 Ed: 12160, train_loss: 1.20375, acc: 0.47317
 Ed: 12800, train_loss: 1.20395, acc: 0.47341
 Ed: 13440, train_loss: 1.20499, acc: 0.47290
 Ed: 14080, train_loss: 1.20380, acc: 0.47349
 Ed: 14720, train_loss: 1.20124, acc: 0.47436
 Ed: 15360, train_loss: 1.19958, acc: 0.47420
 Ed: 16000, train_loss: 1.19876, acc: 0.47454
 Ed: 16640, train_loss: 1.19771, acc: 0.47605
 Ed: 17280, train_loss: 1.19626, acc: 0.47671
 Ed: 17920, train_loss: 1.19448, acc: 0.47720
 Ed: 18560, train_loss: 1.19330, acc: 0.47756
 Ed: 19200, train_loss: 1.19339, acc: 0.47809
 Ed: 19840, train_loss: 1.19227, acc: 0.47865
 Ed: 20480, train_loss: 1.19434, acc: 0.47805
 Ed: 21120, train_loss: 1.19234, acc: 0.47876
 Ed: 21760, train_loss: 1.19157, acc: 0.48034
 Ed: 22400, train_loss: 1.19153, acc: 0.48041
 Ed: 23040, train_loss: 1.19342, acc: 0.48026
 Ed: 23680, train_loss: 1.19392, acc: 0.47936
 Ed: 24320, train_loss: 1.19243, acc: 0.48003
 Ed: 24960, train_loss: 1.19023, acc: 0.48090
 Ed: 25600, train_loss: 1.18882, acc: 0.48126
 Ed: 26240, train_loss: 1.18706, acc: 0.48202
 Ed: 26880, train_loss: 1.18744, acc: 0.48200
 Ed: 27520, train_loss: 1.18763, acc: 0.48180
 Ed: 28160, train_loss: 1.18766, acc: 0.48147
 Ed: 28800, train_loss: 1.18657, acc: 0.48188
 Ed: 29440, train_loss: 1.18592, acc: 0.48271
 Ed: 30080, train_loss: 1.18484, acc: 0.48282
 Ed: 30720, train_loss: 1.18453, acc: 0.48252
 Ed: 31360, train_loss: 1.18415, acc: 0.48301
 Ed: 32000, train_loss: 1.18392, acc: 0.48366
 Ed: 32640, train_loss: 1.18298, acc: 0.48441
 Ed: 33280, train_loss: 1.18338, acc: 0.48458
 Ed: 33920, train_loss: 1.18235, acc: 0.48532
 Ed: 34560, train_loss: 1.18207, acc: 0.48556
 Ed: 35200, train_loss: 1.18223, acc: 0.48551
 Ed: 35840, train_loss: 1.18158, acc: 0.48585
 Ed: 36480, train_loss: 1.18227, acc: 0.48536
 Ed: 37120, train_loss: 1.18212, acc: 0.48532
 Ed: 37760, train_loss: 1.18162, acc: 0.48482
 Ed: 38400, train_loss: 1.18123, acc: 0.48469
 Ed: 39040, train_loss: 1.18011, acc: 0.48504
 Ed: 39680, train_loss: 1.18051, acc: 0.48430
accuracy: 
0.412
macrof: 
0.4302
 Ed: 0, train_loss: 1.12247, acc: 0.42188
 Ed: 640, train_loss: 1.06132, acc: 0.53835
 Ed: 1280, train_loss: 1.02041, acc: 0.56027
 Ed: 1920, train_loss: 1.01684, acc: 0.56149
 Ed: 2560, train_loss: 1.03854, acc: 0.55716
 Ed: 3200, train_loss: 1.05373, acc: 0.54779
 Ed: 3840, train_loss: 1.06365, acc: 0.54329
 Ed: 4480, train_loss: 1.06002, acc: 0.54555
 Ed: 5120, train_loss: 1.05736, acc: 0.54707
 Ed: 5760, train_loss: 1.05586, acc: 0.54808
 Ed: 6400, train_loss: 1.05771, acc: 0.54657
 Ed: 7040, train_loss: 1.05677, acc: 0.54730
 Ed: 7680, train_loss: 1.05553, acc: 0.54403
 Ed: 8320, train_loss: 1.05078, acc: 0.54652
 Ed: 8960, train_loss: 1.05003, acc: 0.54510
 Ed: 9600, train_loss: 1.05079, acc: 0.54284
 Ed: 10240, train_loss: 1.05104, acc: 0.54309
 Ed: 10880, train_loss: 1.05025, acc: 0.54295
 Ed: 11520, train_loss: 1.05042, acc: 0.54316
 Ed: 12160, train_loss: 1.05560, acc: 0.54262
 Ed: 12800, train_loss: 1.05751, acc: 0.54198
 Ed: 13440, train_loss: 1.05944, acc: 0.53888
 Ed: 14080, train_loss: 1.06310, acc: 0.54087
 Ed: 14720, train_loss: 1.06230, acc: 0.54099
 Ed: 15360, train_loss: 1.06925, acc: 0.54085
 Ed: 16000, train_loss: 1.06977, acc: 0.54046
 Ed: 16640, train_loss: 1.06975, acc: 0.54083
 Ed: 17280, train_loss: 1.06821, acc: 0.54215
 Ed: 17920, train_loss: 1.06863, acc: 0.54209
 Ed: 18560, train_loss: 1.06788, acc: 0.54247
 Ed: 19200, train_loss: 1.07104, acc: 0.54101
 Ed: 19840, train_loss: 1.07051, acc: 0.54054
 Ed: 20480, train_loss: 1.07212, acc: 0.54050
 Ed: 21120, train_loss: 1.07102, acc: 0.54097
 Ed: 21760, train_loss: 1.07236, acc: 0.53954
 Ed: 22400, train_loss: 1.07244, acc: 0.53980
 Ed: 23040, train_loss: 1.07446, acc: 0.53952
 Ed: 23680, train_loss: 1.07361, acc: 0.53925
 Ed: 24320, train_loss: 1.07344, acc: 0.53851
 Ed: 24960, train_loss: 1.07185, acc: 0.53908
 Ed: 25600, train_loss: 1.07321, acc: 0.53811
 Ed: 26240, train_loss: 1.07247, acc: 0.53817
 Ed: 26880, train_loss: 1.07243, acc: 0.53815
 Ed: 27520, train_loss: 1.07088, acc: 0.53904
 Ed: 28160, train_loss: 1.06959, acc: 0.53954
 Ed: 28800, train_loss: 1.06772, acc: 0.54053
 Ed: 29440, train_loss: 1.06847, acc: 0.54023
 Ed: 30080, train_loss: 1.06733, acc: 0.54070
 Ed: 30720, train_loss: 1.06610, acc: 0.54109
 Ed: 31360, train_loss: 1.06616, acc: 0.54064
 Ed: 32000, train_loss: 1.06616, acc: 0.54079
 Ed: 32640, train_loss: 1.06606, acc: 0.54143
 Ed: 33280, train_loss: 1.06601, acc: 0.54169
 Ed: 33920, train_loss: 1.06567, acc: 0.54155
 Ed: 34560, train_loss: 1.06628, acc: 0.54136
 Ed: 35200, train_loss: 1.06493, acc: 0.54220
 Ed: 35840, train_loss: 1.06403, acc: 0.54275
 Ed: 36480, train_loss: 1.06414, acc: 0.54307
 Ed: 37120, train_loss: 1.06412, acc: 0.54306
 Ed: 37760, train_loss: 1.06360, acc: 0.54307
 Ed: 38400, train_loss: 1.06362, acc: 0.54279
 Ed: 39040, train_loss: 1.06360, acc: 0.54299
 Ed: 39680, train_loss: 1.06326, acc: 0.54320
accuracy: 
0.4444
macrof: 
0.4476
